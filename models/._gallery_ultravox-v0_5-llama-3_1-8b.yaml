description: |
  Ultravox is a multimodal Speech LLM built around a pretrained Llama3.1-8B-Instruct and whisper-large-v3-turbo backbone.

  See https://ultravox.ai for the GitHub repo and more information.

  Ultravox is a multimodal model that can consume both speech and text as input (e.g., a text system prompt and voice user message). The input to the model is given as a text prompt with a special <|audio|> pseudo-token, and the model processor will replace this magic token with embeddings derived from the input audio. Using the merged embeddings as input, the model will then generate output text as usual.

  In a future revision of Ultravox, we plan to expand the token vocabulary to support generation of semantic and acoustic audio tokens, which can then be fed to a vocoder to produce voice output. No preference tuning has been applied to this revision of the model.
icon: https://avatars.githubusercontent.com/u/153379578
license: llama3.1
urls:
- https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_1-8b
- https://huggingface.co/ggml-org/ultravox-v0_5-llama-3_1-8b-GGUF
name: llama3-instruct
config_file: |
  mmap: true
  function:
    disable_no_action: true
    grammar:
      disable: true
    response_regex:
    - <function=(?P<name>\w+)>(?P<arguments>.*)</function>
  template:
    chat_message: |
      <|start_header_id|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "tool"}}tool{{else if eq .RoleName "user"}}user{{end}}<|end_header_id|>

      {{ if .FunctionCall -}}
      Function call:
      {{ else if eq .RoleName "tool" -}}
      Function response:
      {{ end -}}
      {{ if .Content -}}
      {{.Content -}}
      {{ else if .FunctionCall -}}
      {{ toJson .FunctionCall -}}
      {{ end -}}
      <|eot_id|>
    function: |
      <|start_header_id|>system<|end_header_id|>

      You have access to the following functions:

      {{range .Functions}}
      Use the function '{{.Name}}' to '{{.Description}}'
      {{toJson .Parameters}}
      {{end}}

      Think very carefully before calling functions.
      If a you choose to call a function ONLY reply in the following format with no prefix or suffix:

      <function=example_function_name>{{`{{"example_name": "example_value"}}`}}</function>

      Reminder:
      - If looking for real time information use relevant functions before falling back to searching on internet
      - Function calls MUST follow the specified format, start with <function= and end with </function>
      - Required parameters MUST be specified
      - Only call one function at a time
      - Put the entire function call reply on one line
      <|eot_id|>
      {{.Input }}
      <|start_header_id|>assistant<|end_header_id|>
    chat: |
      {{.Input }}
      <|start_header_id|>assistant<|end_header_id|>
    completion: |
      {{.Input}}
  context_size: 8192
  f16: true
  stopwords:
  - <|im_end|>
  - <dummy32000>
  - "<|eot_id|>"
  - <|end_of_text|>
files:
- filename: Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
  sha256: 7b064f5842bf9532c91456deda288a1b672397a54fa729aa665952863033557c
  uri: huggingface://ggml-org/ultravox-v0_5-llama-3_1-8b-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
- filename: mmproj-ultravox-v0_5-llama-3_1-8b-f16.gguf
  sha256: e6395ed42124303eaa9fca934452aabce14c59d2a56fab2dda65b798442289ff
  uri: https://huggingface.co/ggml-org/ultravox-v0_5-llama-3_1-8b-GGUF/resolve/main/mmproj-ultravox-v0_5-llama-3_1-8b-f16.gguf
prompt_templates: []
