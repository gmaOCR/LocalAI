# üîß R√©solution du probl√®me Backend Inpainting

## ‚ùå Probl√®me identifi√©

```
5:34PM ERR Backend not found: stablediffusion-ggml
5:34PM ERR Failed to load model sd-3.5-large-ggml with backend stablediffusion-ggml
```

## üîç Analyse

### 1. **Architecture modulaire de LocalAI**

LocalAI v3.2+ utilise une architecture o√π les backends sont **s√©par√©s du binaire principal** et doivent √™tre install√©s/charg√©s dynamiquement.

### 2. **Logique de s√©lection de mod√®le**

Voici comment LocalAI s√©lectionne le mod√®le:

```
1. Le frontend envoie: model="dreamshaper-8-inpainting"
2. Le middleware cherche une config pour ce mod√®le
3. Si non trouv√© ‚Üí utilise le premier mod√®le disponible (sd-3.5-large-ggml)
4. Charge le backend associ√© (stablediffusion-ggml)
5. ‚ùå ERREUR: Backend non install√© dans l'image
```

**Log explicatif:**
```
5:34PM DBG context local model name not found, setting to the first model
5:34PM DBG overriding empty model name in request body with value found earlier
```

## ‚úÖ Solutions

### Solution 1: Installer le backend stablediffusion-ggml

Le backend doit √™tre install√© dans l'image Docker. Modifions le Dockerfile:

```dockerfile
# Apr√®s la copie du binaire, installer les backends n√©cessaires
RUN /usr/local/bin/local-ai backends install stablediffusion-ggml
```

### Solution 2: Utiliser un backend Python (diffusers)

Alternative avec le backend Python qui supporte l'inpainting:

```dockerfile
RUN /usr/local/bin/local-ai backends install diffusers
```

### Solution 3: Cr√©er une configuration de mod√®le

Cr√©er un fichier de configuration pour votre mod√®le:

**`/models/dreamshaper-8-inpainting.yaml`**
```yaml
name: dreamshaper-8-inpainting
backend: diffusers  # ou stablediffusion-ggml si install√©
parameters:
  model: runwayml/stable-diffusion-inpainting
  # Ou pour ggml:
  # model: /models/dreamshaper-8-inpainting.gguf
```

## üöÄ Solution recommand√©e

### √âtape 1: Modifier le Dockerfile pour inclure les backends

```dockerfile
# Dans docker/Dockerfile.inpainting, apr√®s la copie du binaire:

# Install required backends for inpainting
RUN /usr/local/bin/local-ai backends install stablediffusion-ggml && \
    /usr/local/bin/local-ai backends install diffusers
```

### √âtape 2: Rebuild et push

```bash
./scripts/build-and-push.sh
```

### √âtape 3: Configuration c√¥t√© serveur

Cr√©er les configurations de mod√®les dans `/models/`:

**`/models/dreamshaper-8-inpainting.yaml`**
```yaml
name: dreamshaper-8-inpainting
backend: stablediffusion-ggml
parameters:
  model: /models/dreamshaper-8-inpainting.gguf
  step: 25
  cfg_scale: 7.0
```

## üîÑ Workaround imm√©diat (sans rebuild)

Si vous ne voulez pas rebuilder l'image maintenant:

### Option A: Installer le backend au runtime

```bash
docker exec -it votre-conteneur /usr/local/bin/local-ai backends install stablediffusion-ggml
```

### Option B: Utiliser le mod√®le existant

Modifiez votre frontend pour utiliser le mod√®le d√©j√† charg√©:

```javascript
// Au lieu de:
model: "dreamshaper-8-inpainting"

// Utilisez:
model: "sd-3.5-large-ggml"
```

### Option C: Monter les backends depuis l'h√¥te

```bash
docker run -d -p 8080:8080 \
  -v /path/to/models:/models \
  -v /path/to/backends:/backends \  # ‚Üê Montez les backends
  mercure.gregorymariani.com/localai:inpainting-latest
```

## üìã V√©rification des backends disponibles

Pour voir quels backends sont install√©s:

```bash
# Dans le conteneur
docker exec votre-conteneur ls -la /backends

# Ou via l'API
curl http://localhost:8080/backends/available
```

## üéØ Prochaines √©tapes recommand√©es

1. **Court terme**: Utiliser le mod√®le `sd-3.5-large-ggml` qui est d√©j√† charg√©
2. **Moyen terme**: Cr√©er une nouvelle image avec les backends pr√©-install√©s
3. **Long terme**: Configurer un syst√®me de gestion de mod√®les automatique

---

**Voulez-vous que je modifie le Dockerfile pour inclure les backends n√©cessaires et rebuilder l'image?**
